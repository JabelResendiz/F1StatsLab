{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis para la prediccion de Tiempo de Vuelta usando Regresion Lineal Multiple\n",
    "\n",
    "\n",
    "`Melbourne` (Gran Premio de Australia) es un circuito urbano ubicado en Albert Park, `Melbourne`. Con una longitud de 5303 metros, se caracteriza por ser una pista mixta que combina secciones de alta velocidad con curvas técnicas. Aunque es un circuito que se corre en sentido horario, las zonas más difíciles son aquellas con múltiples cambios de dirección, lo que exige un alto nivel de control y precisión.\n",
    "\n",
    "El clima en `Melbourne` es impredecible, con cambios repentinos de temperatura y posibles lluvias que complican las estrategias de los equipos. Las curvas de alta velocidad y las rectas relativamente cortas hacen que las paradas en boxes sean cruciales para los pilotos. Por lo tanto, es esencial tener un buen manejo de los neumáticos, especialmente en las zonas donde el asfalto es más abrasivo. El desempeño en la frenada y las aceleraciones de las curvas 1 y 3 son clave para conseguir tiempos rápidos.\n",
    "\n",
    "![Melbourne](../img/melbourne.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos entonces un estudio de un modelo de regresión lineal múltiple con variable dependiente `FinalRaceTime` en el circuito de Melbourne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared: 0.2256\n",
      "\n",
      "R-squared: 0.2255\n",
      "\n",
      "R-squared: 0.1993\n",
      "\n",
      "R-squared: 0.1953\n",
      "\n",
      "R-squared: 0.1953\n",
      "\n",
      "R-squared: 0.2244\n",
      "\n",
      "R-squared: 0.2983\n",
      "\n",
      "R-squared: 0.3258\n",
      "\n",
      "R-squared: 0.3554\n",
      "\n",
      "R-squared: 0.3577\n",
      "\n",
      "R-squared: 0.3301\n",
      "\n",
      "R-squared: 0.2473\n",
      "\n",
      "R-squared: 0.1644\n",
      "\n",
      "R-squared: 0.2709\n",
      "\n",
      "R-squared: 0.3565\n",
      "['MaxSpeed', 'Age', 'FinalPosition', 'Points', 'Overtakes', 'TyreWear', 'WeatherCondition_Mixed', 'TrackGrip_Low']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "def load_data(filepath, circuit_name):\n",
    "    data = pd.read_csv(filepath)\n",
    "    circuit_data = data[data['Circuit'] == circuit_name].copy()\n",
    "    if circuit_data.empty:\n",
    "        raise ValueError(f\"No data found for circuit {circuit_name}\")\n",
    "    return circuit_data\n",
    "\n",
    "def select_features(data, target, initial_features):\n",
    "    features = [f for f in initial_features if f in data.columns]\n",
    "    if target not in data.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in the dataset\")\n",
    "    return features\n",
    "\n",
    "def preprocess_data(data, features, target):\n",
    "    for feature in features:\n",
    "        data[feature] = pd.to_numeric(data[feature], errors='coerce')\n",
    "    data = data.dropna(subset=features + [target])\n",
    "    return data\n",
    "\n",
    "def train_model(X, y):\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    # Create and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Print the equation of the hyperplane\n",
    "    coefficients = model.coef_\n",
    "    intercept = model.intercept_\n",
    "\n",
    "    #print(\"\\nEquation of the hyperplane:\")\n",
    "    equation = f\"FinalRiceTime = {intercept:.2f}\"\n",
    "    for feature, coef in zip(features, coefficients):\n",
    "        equation += f\" + ({coef:.2f} * {feature})\"\n",
    "    #print(equation)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r_squared = model.score(X_test_scaled, y_test)\n",
    "    print(f\"\\nR-squared: {r_squared:.4f}\")\n",
    "    \n",
    "   \n",
    "# Agregar constante para la intersección\n",
    "    X_train_const = sm.add_constant(X_train_scaled)\n",
    "\n",
    "\n",
    "# Ajustar el modelo de regresión con statsmodels\n",
    "    model_sm = sm.OLS(y_train, X_train_const).fit()\n",
    "\n",
    "# Mostrar los p-values de cada coeficiente\n",
    "    #print(model_sm.summary())\n",
    "\n",
    "# Create a DataFrame for coefficients and p-values\n",
    "    summary_df = pd.DataFrame({\n",
    "    'Feature': model_sm.params.index,\n",
    "    'Coefficient': model_sm.params.values,\n",
    "    'P-value': model_sm.pvalues.values\n",
    "    })\n",
    "\n",
    "# Filter to keep only p-values greater than 0.05\n",
    "    summary_df = summary_df[summary_df['P-value'] > 0.05]\n",
    "\n",
    "# Sort the DataFrame by p-value in descending order\n",
    "    summary_df = summary_df.sort_values(by='P-value', ascending=False)\n",
    "\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "    # print(\"\\nSorted Coefficients and P-values (from highest to lowest p-value):\")\n",
    "    # print(summary_df)\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "\n",
    "# Ejecutar el pipeline\n",
    "data = load_data(\"formula1_interlagos_df_final.csv\", \"Melbourne\")\n",
    "features = ['MaxSpeed', 'DriverSkill', 'Age', 'PitStopTime', 'ReactionTime',\n",
    "                    'FinalPosition', 'Experience', 'DNF', 'Points', 'Overtakes', 'TyreWear',\n",
    "                    'CarPerformance', 'TrackFamiliarity', 'FuelConsumption', 'DownforceLevel',\n",
    "                    'TrackTemperature', 'WeatherCondition_Mixed', 'WeatherCondition_Wet',\n",
    "                    'TyreCompound_Medium', 'TyreCompound_Soft', 'TrackGrip_Low', 'TrackGrip_Medium']\n",
    "\n",
    "target = 'FinalRaceTime'\n",
    "features = select_features(data, target, features)\n",
    "data = preprocess_data(data, features, target)\n",
    "X, y = data[features], data[target]\n",
    "\n",
    "summary_df = train_model(X, y)\n",
    "\n",
    "while len(summary_df)>0:\n",
    "    top_feature = str(summary_df.iloc[0]['Feature']) # Primer variable (con mayor p-valor)\n",
    "    \n",
    "    #print(top_feature[1:])\n",
    "    \n",
    "    del features[int(top_feature[1:])-1]\n",
    "    #print(f\"Variable {top_feature} eliminada de 'features'.\")\n",
    "    #print(f\"Lista de variables restantes: {features}\")\n",
    "    \n",
    "    features = select_features(data, target, features)\n",
    "    data = preprocess_data(data, features, target)\n",
    "    X, y = data[features], data[target]\n",
    "    summary_df = train_model(X, y)\n",
    "    \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí hemos podido ver que aplicamos un método de selección de características basado en `backward elimination`. En cada iteración, eliminamos la variable con el mayor p-valor (es decir, la menos significativa), y repetimos el proceso hasta que todas las variables restantes tienen un p-valor menor a 0.05, lo que sugiere que son estadísticamente significativas para predecir el tiempo final de la carrera. Finalmente, nos hemos quedado con un conjunto reducido de variables independientes que tienen una mayor relación con el objetivo de la predicción, FinalRaceTime, lo que mejora la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
